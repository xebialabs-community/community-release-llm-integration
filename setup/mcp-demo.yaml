---
apiVersion: xl-release/v1
kind: Templates
metadata:
  home: AI Demo
spec:

  # MCP Servers
  - name: Agility MCP Server
    type: community-llm.McpServer
    url: https://api.staging.digital.ai/agilitymcp/v1/mcp
    headers:
      X-Agility-Bearer: !value AGILITY_KEY
      X-Agility-Host: https://www7.v1host.com/V1Production

  - name: Release MCP Server
    type: community-llm.McpServer
    url: http://host.docker.internal:8000/mcp

  - name: GitHub MCP Server
    type: community-llm.McpServer
    url: https://api.githubcopilot.com/mcp/
    headers:
      Authorization: !value GITHUB_TOKEN

    # AI Models
  - name: Gemini 2.5 Pro
    type: community-llm.GeminiModel
    apiKey: !value GEMINI_API_KEY
    model_id: gemini-2.5-pro

  - name: Gemini 2.5 Flash
    type: community-llm.GeminiModel
    apiKey: !value GEMINI_API_KEY
    model_id: gemini-2.5-flash

  - name: Gemini 2.5 Flash-Lite
    type: community-llm.GeminiModel
    apiKey: !value GEMINI_API_KEY
    model_id: gemini-2.5-flash-lite

  - name: Amazon Nova Micro 1:0
    type: community-llm.DaiLlmModel
    url: https://api.staging.digital.ai/llm
    apiKey: !value DAI_LLM_API_KEY
    model_id: amazon.nova-micro-v1:0

  - name: Anthropic Sonnet 4.5
    type: community-llm.DaiLlmModel
    url: https://api.staging.digital.ai/llm
    apiKey: !value DAI_LLM_API_KEY
    model_id: anthropic.claude-sonnet-4-5-20250929-v1:0

  - name: OpenAI GPT 5
    type: community-llm.OpenAiModel
    apiKey: !value OPENAI_API_KEY
    model_id: gpt-5

  - name: OpenAI GPT 5 mini
    type: community-llm.OpenAiModel
    apiKey: !value OPENAI_API_KEY
    model_id: gpt-5-mini

  - name: OpenAI GPT 5 nano
    type: community-llm.OpenAiModel
    apiKey: !value OPENAI_API_KEY
    model_id: gpt-5-nano

  # Demo Templates
  - template: 1. MCP examples
    description: |
      Demo template to show different uses of the **MCP: Call tool** task.
    phases:
      - phase: Call tool
        tasks:
          - name: "Release: List folders"
            type: community-llm.McpCallTool
            server: Release MCP Server
            tool: list_folders
            input: |-
              {
                "request": {}
              }
          - name: "GitHub: Get my details"
            type: community-llm.McpCallTool
            server: GitHub MCP Server
            tool: get_me
          - name: "GitHub: Read sample issue"
            type: community-llm.McpCallTool
            server: GitHub MCP Server
            tool: issue_read
            input: |-
              {
              "issue_number": 1,
              "method": "get",
              "owner": "xebialabs-community",
              "repo": "community-release-llm-integration"
              }
            result: ${issue}
        color: "#3d6c9e"
    variables:
      - type: xlrelease.StringVariable
        key: issue
        requiresValue: false
        showOnReleaseStart: false
        label: Issue
        description: The issue json from GitHub
  - template: 2. Prompt examples
    description: |
      "Hello world" example of the **AI: Prompt** task with different models.
    phases:
      - phase: Hello world
        tasks:
          - name: Hello world (Gemini)
            type: community-llm.LlmPrompt
            taskFailureHandlerEnabled: true
            taskRecoverOp: SKIP_TASK
            prompt: "Say hello world in six languages, one for each continent"
            model: Gemini 2.5 Flash-Lite
          - name: Hello world (OpenAI)
            type: community-llm.LlmPrompt
            taskFailureHandlerEnabled: true
            taskRecoverOp: SKIP_TASK
            prompt: "Say hello world in six languages, one for each continent"
            model: OpenAI GPT 5 nano
          - name: Hello world (Digital.ai LLM Service)
            type: community-llm.LlmPrompt
            taskFailureHandlerEnabled: true
            taskRecoverOp: SKIP_TASK
            prompt: "Say hello world in six languages, one for each continent"
            model: Amazon Nova Micro 1:0
        color: "#3d6c9e"
  - template: 3. MCP + Prompt examples
    description: |
      Shows how to combine the **MCP: Call tool** task with the **AI: prompt** task for further processing.
    phases:
      - phase: User details
        tasks:
          - name: "GitHub: Get my details"
            type: community-llm.McpCallTool
            server: GitHub MCP Server
            tool: get_me
            result: ${user}
          - name: Get name
            type: community-llm.LlmPrompt
            prompt: |-
              Extract the name from the following data. Give me only the full name as a result
              
              ```
              ${user}
              ```
            model: Gemini 2.5 Flash
            response: ${name}
          - name: Get summary
            type: community-llm.LlmPrompt
            prompt: |-
              Please create a nice summary of the following data
              
              ```
              ${user}
              ```
            model: Gemini 2.5 Flash
            response: ${summary}
          - name: "Verify summary for ${name}"
            type: xlrelease.GateTask
            description: "${summary}"
            owner: admin
      - phase: List failed releases
        tasks:
          - name: Find failed releases
            type: community-llm.McpCallTool
            server: Release MCP Server
            tool: list_releases
            input: |-
              {
                "request": 
                {
                 "failed": true
                }
              }
            result: ${releases}
          - name: Create a summary
            type: community-llm.LlmPrompt
            prompt: |-
              Make a summary of the failed releases:
              
              ```
              ${releases}
              ```
            model: Gemini 2.5 Flash
            response: ${release_summary}
          - name: Verify
            type: xlrelease.GateTask
            description: |-
              ## Failed releases
              
              ${release_summary}
            owner: admin
        color: "#3d6c9e"
    variables:
      - type: xlrelease.StringVariable
        key: user
        requiresValue: false
        showOnReleaseStart: false
        label: User info
        description: JSON info of user
      - type: xlrelease.StringVariable
        key: summary
        requiresValue: false
        showOnReleaseStart: false
        label: User summary
        description: The response from Google Gemini
      - type: xlrelease.StringVariable
        key: name
        requiresValue: false
        showOnReleaseStart: false
        label: User name
        description: Subject of the message.
      - type: xlrelease.StringVariable
        key: releases
        requiresValue: false
        showOnReleaseStart: false
        label: ßReleases
        description: Result
      - type: xlrelease.StringVariable
        key: release_summary
        requiresValue: false
        showOnReleaseStart: false
        label: Failed release summary
  - template: 4. Agent examples
    description: |
      Example usage of the **AI: Agent** task
    phases:
      - phase: Agent with MCP
        tasks:
          - name: Create user summary
            type: community-llm.LlmAgent
            prompt: Create a nice summary for the currently logged in user.
            model: Gemini 2.5 Flash
            mcpServer1: GitHub MCP Server
            result: ${summary}
          - name: Verify
            type: xlrelease.GateTask
            description: |-
              ## User details
              
              ${summary}
            owner: admin
        color: "#3d6c9e"
      - phase: Check phases
        tasks:
          - name: Analyze templates
            type: community-llm.LlmAgent
            prompt: Analyze all templates in the "AI Demo" folder and report on tasks that
              are duplicated across templates.
            model: Gemini 2.5 Flash
            mcpServer1: Release MCP Server
            result: ${duplicates}
          - name: Verify
            type: xlrelease.GateTask
            description: |-
              ## Template summary
              
              ${duplicates}
        color: "#3d6c9e"
      - phase: Multiple MCP servers
        tasks:
          - name: Create GitHub ticket for last failed release
            type: community-llm.LlmAgent
            description: |-
              Attempt to make the agent "create a ticket for the last release that failed"
              
              ⚠️ Not working yet. The agent / models seem to get very confused and tend to give up.
            prompt: |-
              List all releases in Digital.ai Release.
              
              For the last release in FAILED state, create a GitHub issue in xebialabs-community/community-release-llm-integration repo to fix it.
              
              Mention Release title, date and cause in the ticket
            model: Gemini 2.5 Pro
            mcpServer1: Release MCP Server
            mcpServer2: GitHub MCP Server
          - name: Verify
            type: xlrelease.GateTask
            description: |-
              Check if there is a new issue created here:
              
              * https://github.com/xebialabs-community/community-release-llm-integration/issues
            owner: admin
        color: "#3d6c9e"
    variables:
      - type: xlrelease.StringVariable
        key: summary
        requiresValue: false
        showOnReleaseStart: false
        label: Result
        description: The result returned by the agent
      - type: xlrelease.StringVariable
        key: duplicates
        requiresValue: false
        showOnReleaseStart: false
        label: Result
        description: The result returned by the agent
  - template: 5.  Interactive Chat example
    phases:
      - phase: Prompt
        tasks:
          - name: Chat with agent
            type: community-llm.LlmChat
            model: Amazon Nova Micro 1:0
          - name: OK?
            type: xlrelease.GateTask
            owner: admin
    scriptUsername: admin
    scriptUserPassword: admin

  - template: Tasks for README screenshots
    variables:
      - type: xlrelease.StringVariable
        key: issue
        requiresValue: false
        showOnReleaseStart: false
        label: Issue
        description: The issue json from GitHub
    scriptUsername: admin
    scriptUserPassword: admin
    phases:
      - phase: Examples
        color: "#3d6c9e"
        tasks:
          - name: Report failed releases
            type: community-llm.LlmAgent
            description: Use an agent to automate your workflow
            prompt: |-
              Create a ticket for each failed release.
              
              Use the issue list in xebialabs-community/community-release-llm-integration
            model: Anthropic Sonnet 4.5
            mcpServer1: Release MCP Server
            mcpServer2: GitHub MCP Server

          - name: Say hello
            type: community-llm.LlmPrompt
            prompt: Say hello in 6 languages for 6 continents
            model: Amazon Nova Micro 1:0

          - name: Interactive chat
            type: community-llm.LlmChat
            model: Gemini 2.5 Flash

          - name: Read GitHub issue
            type: community-llm.McpCallTool
            description: Read issue number `1` from GitHub repo **community-release-llm-integration**
            result: ${issue}
            server: GitHub MCP Server
            tool: issue_read
            input: |-
              {
              "issue_number": 1,
              "method": "get",
              "owner": "xebialabs-community",
              "repo": "community-release-llm-integration"
              }

          - name: List Release MCP tools
            type: community-llm.McpListToolsTask
            description: Lists all MCP tools for this Release server
            server: Release MCP Server

